{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9076dd4d",
   "metadata": {},
   "source": [
    "# Agentic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f81d636f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pprint\n",
    "from dotenv import load_dotenv\n",
    "from typing import Annotated, Sequence, Literal\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader, csv_loader\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.schema import Document\n",
    "\n",
    "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "713f7f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0273e01f",
   "metadata": {},
   "source": [
    "## Téléchargement du CSV\n",
    "\n",
    "Arguments ajoutées pour que les métadonnées prennent en compte la date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e05c1932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 documents from CSV file.\n",
      "First document metadata:\n",
      "{'source': 'datas/short_APPL.csv', 'row': 0, 'date': '2023-12-16 22:00:00 UTC'}\n",
      "First document content:\n",
      ": 0\n",
      "article: After an absolute disaster of a year in 2022, the stock market appears to have turned the corner. Each of the major market indexes has gained more than 20% from their respective trough. Perhaps more importantly, the S&P 500 and the Nasdaq Composite are within striking distance of new highs, which will check the final box marking the start of a new bull market.\n",
      "Closing out the old and ringing in the new is a great time for examination, and one of the places I start is with my portfolio. A review of my top investments and how they came to be that way can offer valuable insight for the future.\n",
      "Here's a look at my six largest holdings heading into 2024 (as of the market close on Dec. 15) and the incredibly valuable lesson I learned from each one.\n",
      "Image source: Getty Images.\n",
      "No. 6: Nvidia\n",
      "Every investor has one -- the \"stock that got away.\" The one you meant to buy, only to find that it got away from you and has risen 100%, 500%, or even 1,000%. In my case, that stock was Nvidia (NASDAQ: NVDA). I had owned a few shares of the graphics processing units (GPU) pioneer in the early days of my investing journey but ultimately sold them in an unprovoked bid of tax-loss harvesting in early 2010.\n",
      "I always meant to buy it back, but the stock price meandered for much of the next five years, and I ultimately lost confidence. Things changed quickly in 2016 when the stock tripled. After that, it just kept getting away from me.\n",
      "Fast forward to early 2018. Nvidia still dominated the discrete desktop GPU space, controlling roughly 70% of the market. The company's graphics cards were the processor of choice for cryptocurrency mining, which was booming. Furthermore, there was an ongoing push toward autonomous driving. It was clear that CEO Jensen Huang had a knack for skating to where the puck was going -- recognizing technology trends on the fly and adapting Nvidia's processors and the accompanying software to meet that need.\n",
      "After much deliberation, I held my nose and bought Nvidia anyway -- even though the stock had risen 600% over the preceding two years. I have added to my stake several times since. Over the past few years, Nvidia has once again adapted to meet a compelling technology need, becoming the gold standard for generative AI applications.\n",
      "Since that initial purchase, Nvidia has soared 768%, and the stock has become my sixth-largest holding, amounting to nearly 6% of my portfolio. The lesson here? It's never too late to buy a quality company, even if the stock has already risen many times over.\n",
      "No. 5 and 4: Shopify and Amazon\n",
      "Long after Amazon had established itself as the world's largest digital retailer, Shopify (NYSE: SHOP) came on the scene with a different approach to e-commerce. Shopify's founders, having discovered firsthand the difficulties inherent in starting an online sales platform, pivoted the business from selling snowboards to providing customizable templates and other tools that made setting up and running an e-commerce business a snap.\n",
      "By solving a common problem among digital retailers, Shopify carved out a profitable niche for itself in a market that was already (and still is) dominated by Amazon. While it isn't an exact apples-to-apples comparison, it helps illustrate an age-old truth in investing that I learned from owning this stock -- there's a Pepsi for every Coke.\n",
      "There's another lesson here. I had long been a shareholder of Amazon, but I recognized the value Shopify could bring to the online sales space. Despite the fact that e-commerce was already well represented in my portfolio, I made a sizable investment in Shopify.\n",
      "That decision turned out well, as both companies have continued to prosper in the age of digital retail. It also turned out well for me as an investor. Since my first purchase of Shopify shares, the stock is up more than 1,446%, while Amazon has gained 844%. Shopify and Amazon are my fourth and fifth largest holdings heading into 2024, each representing roughly 6% of my portfolio.\n",
      "No. 3: Apple\n",
      "There's little question that Apple (NASDAQ: AAPL) has become one of the most successful companies in history. Yet, at times over the past few years, some investors concluded the company had reached its zenith. Apple reached a market cap of $1 trillion in 2018, so how much higher could it go?\n",
      "There were other worries. As penetration has risen, global smartphone sales have slowed. Since Apple's flagship product -- the iPhone -- historically generates more than half the company's revenue, investor reservations are understandable.\n",
      "Despite these challenges, Apple has continued to grow. CEO Tim Cook has succeeded in expanding Apple's services business to become the company's second-biggest breadwinner, behind just the iPhone. The segment brought in $85 billion in fiscal 2023 (ended Sept. 30), making it comparable to a top 50 company in the Fortune 500. Furthermore, the iPhone continues to dominate where it matters, capturing a record 45% of worldwide smartphone revenue and 85% of profits in the second quarter, according to Counterpoint Research.\n",
      "Fears that Apple simply couldn't go any higher turned out to be unfounded, an important lesson for investors as its market cap has tripled since 2018. Since my first purchase in 2008, Apple's stock price has surged more than 3,400% to become my third-largest position at 8% of my portfolio. I'm confident there's more to come.\n",
      "No. 2: Mercadolibre\n",
      "It's likely that many investors have never heard of MercadoLibre (NASDAQ: MELI). The company, which began as a local online auction site, has evolved into the largest e-commerce and payments ecosystem in Latin America, serving 18 countries in the region.\n",
      "MercadoLibre not only provides a marketplace for buyers and sellers but also handles shipping and logistics, warehouse and cross-docking, digital payments, consumer and merchant financing, digital wallets, and more. Think of it as the Amazon, Shopify, and PayPal of Latin America all rolled into one.\n",
      "Many investors have avoided the stock because of the risks inherent in the region, which is understandable. For example, Argentina -- MercadoLibre's birthplace and one of its biggest markets -- has an inflation rate that clocks in at 143%, and the country just devalued its currency by 50%. Other countries in the region grapple with hyperinflation, economic turmoil, charges of political corruption, poor infrastructure, and more.\n",
      "Yet those risks pale in the context of the opportunity. Latin America is years behind the U.S. in terms of e-commerce and digital payment penetration, yet adoption continues to grow. Furthermore, Latin America has twice the population of the U.S. and is the fastest-growing e-commerce market in the world, according to Americas Market Intelligence. Finally, because MercadoLibre takes a cut of each transaction, it has sidestepped many of those risks. As a result, its revenue grew 50% in 2022 while net income soared 480%, a trend that has been ongoing for more than a decade.\n",
      "Understanding the risk, viewed through the lens of the significant long-term opportunity, can provide important insight, which gave me the confidence to buy the stock. My rather modest initial investment in MercadoLibre in 2009 has grown by more than 7,300%, and the company now represents 10% of my portfolio. Not bad for a \"risky\" stock.\n",
      "No. 1: Netflix\n",
      "Netflix (NASDAQ: NFLX) was the very first stock I bought when I started investing in late 2007. After incurring a late fee at Blockbuster (remember them?) that was more than the cost of buying the movie new, I cut up my membership card and subscribed to Netflix. As an extremely satisfied customer, it made perfect sense to buy the stock once I started investing.\n",
      "Back then, the company was a DVD-by-mail service that had recently begun experimenting with streaming video. Netflix had achieved remarkable penetration in its earliest markets, and I surmised the company could expand its success across the country, which was the basis of my investing thesis.\n",
      "The company has achieved all that and more, becoming the world's largest subscription streaming video service. The value of the initial shares I bought in 2007 has surged more than 19,000%, making Netflix my largest holding at nearly 11% of my portfolio.\n",
      "However, those life-changing gains were only possible because I held the stock for the duration, which is easier said than done. Remember the \"Qwikster\" fiasco of 2011? All the \"Netflix killers\" over the years? How about the loss of 1.2 million subscribers early last year?\n",
      "There were plenty of excuses to sell Netflix over the years, but for me, the investing thesis never changed, so I held on. And this long-term buy-and-hold strategy continues to win out.\n",
      "Should you invest $1,000 in Nvidia right now?\n",
      "Before you buy stock in Nvidia, consider this:\n",
      "The Motley Fool Stock Advisor analyst team just identified what they believe are the 10 best stocks for investors to buy now... and Nvidia wasn't one of them. The 10 stocks that made the cut could produce monster returns in the coming years.\n",
      "Stock Advisor provides investors with an easy-to-follow blueprint for success, including guidance on building a portfolio, regular updates from analysts, and two new stock picks each month. The Stock Advisor service has more than tripled the return of S&P 500 since 2002*.\n",
      "See the 10 stocks\n",
      "*Stock Advisor returns as of December 11, 2023\n",
      "John Mackey, former CEO of Whole Foods Market, an Amazon subsidiary, is a member of The Motley Fool’s board of directors. Danny Vena has positions in Amazon, Apple, MercadoLibre, Netflix, Nvidia, PayPal, and Shopify and has the following options: long January 2024 $95 calls on PayPal. The Motley Fool has positions in and recommends Amazon, Apple, MercadoLibre, Netflix, Nvidia, PayPal, and Shopify. The Motley Fool recommends the following options: long January 2024 $47.50 calls on Coca-Cola and short December 2023 $67.50 puts on PayPal. The Motley Fool has a disclosure policy.\n",
      "The views and opinions expressed herein are the views and opinions of the author and do not necessarily reflect those of Nasdaq, Inc.\n"
     ]
    }
   ],
   "source": [
    "loader = csv_loader.CSVLoader(\n",
    "    file_path=\"datas/short_APPL.csv\",\n",
    "    metadata_columns=[\"date\"],\n",
    "    encoding=\"utf-8\",\n",
    "    csv_args={\n",
    "        \"delimiter\": \",\",\n",
    "        \"quotechar\": '\"',\n",
    "    })\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(docs)} documents from CSV file.\")\n",
    "print(f\"First document metadata:\\n{docs[0].metadata}\")\n",
    "print(f\"First document content:\\n{docs[0].page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20677602",
   "metadata": {},
   "source": [
    "## Encodage\n",
    "\n",
    "split le document en chunks<br/>\n",
    "et embedding avec un modèle HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2dddada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 173\n",
      "First chunk: : 0\n",
      "article: After an absolute disaster of a year in 2022, the stock market appears to have turned the corner. Each of the major market indexes has gained more than 20% from their respective trough. Perhaps more importantly, the S&P 500 and the Nasdaq Composite are within striking distance of new highs, which will check the final box marking the start of a new bull market.\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=50,\n",
    ")\n",
    "docs_splits = text_splitter.split_documents(docs)\n",
    "print(f\"Total chunks: {len(docs_splits)}\")\n",
    "print(f\"First chunk: {docs_splits[0].page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3bee76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte : : 0\n",
      "article: After an absolute disaster of a year in 2022, the stock market appears to have turned the corner. Each of the major market indexes has gained more than 20% from their respective trough. Perhaps more importantly, the S&P 500 and the Nasdaq Composite are within striking distance of new highs, which will check the final box marking the start of a new bull market.\n",
      "Date : 2023-12-16 22:00:00 UTC\n",
      "------\n",
      "Texte : Closing out the old and ringing in the new is a great time for examination, and one of the places I start is with my portfolio. A review of my top investments and how they came to be that way can offer valuable insight for the future.\n",
      "Here's a look at my six largest holdings heading into 2024 (as of the market close on Dec. 15) and the incredibly valuable lesson I learned from each one.\n",
      "Image source: Getty Images.\n",
      "No. 6: Nvidia\n",
      "Date : 2023-12-16 22:00:00 UTC\n",
      "------\n",
      "Texte : Every investor has one -- the \"stock that got away.\" The one you meant to buy, only to find that it got away from you and has risen 100%, 500%, or even 1,000%. In my case, that stock was Nvidia (NASDAQ: NVDA). I had owned a few shares of the graphics processing units (GPU) pioneer in the early days of my investing journey but ultimately sold them in an unprovoked bid of tax-loss harvesting in early 2010.\n",
      "Date : 2023-12-16 22:00:00 UTC\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "for chunk in docs_splits[:3]:\n",
    "    print(\"Texte :\", chunk.page_content)\n",
    "    print(\"Date :\", chunk.metadata.get(\"date\"))\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1c8f33",
   "metadata": {},
   "source": [
    "## Contextualiser les chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29a9abc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buid_contextual_chunks(chunks, window=2):\n",
    "    contextual_chunks=[]\n",
    "    for i in range(len(chunks)):\n",
    "        start = max(i - window,0)\n",
    "        end = min(i + window + 1, len(chunks))\n",
    "        combined_text = \"\\n\".join([chunks[j].page_content for j in range(start, end)])\n",
    "\n",
    "        metadata = chunks[i].metadata.copy()\n",
    "        contextual_chunks.append(Document(page_content=combined_text, metadata=metadata))\n",
    "    return contextual_chunks\n",
    "\n",
    "contextual_docs = buid_contextual_chunks(docs_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ef597fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_862/614348645.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(\n",
      "/var/www/html/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1039396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = \"./chroma_db\"\n",
    "os.makedirs(persist_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bee9c33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorestore = Chroma.from_documents(\n",
    "    documents=contextual_docs,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "retriever = vectorestore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35850bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retrieve_apple_news\",\n",
    "    \"Search and return information from press articles about Apple Inc., including news related to its stock market activity, financial performance, and business developments.\",\n",
    ")\n",
    "tools = [retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "047d1500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.4\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "print(chromadb.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06994da3",
   "metadata": {},
   "source": [
    "## Agent State\n",
    "\n",
    "Création de la classe AgentState\n",
    "création des différentes Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c764aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "   messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedce291",
   "metadata": {},
   "source": [
    "différentes fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "012ddcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_documents(state) -> Literal[\"generate\", \"rewrite\"]:\n",
    "    \"\"\"\n",
    "    Détermine si les documents récupérés sont pertinents par rapport à la question.\n",
    "    \n",
    "    Args :\n",
    "        state (messages): L'état des messages du système.\n",
    "        \n",
    "    Returns :\n",
    "        str: Une décision quant à savoir si les documents sont pertinents ou non\n",
    "    \"\"\"\n",
    "    print(\"---CHECK RELEVANCE---\")\n",
    "\n",
    "    # Data model\n",
    "    class grade(BaseModel):\n",
    "        \"\"\"Score binaire pour la vérification de la pertinence.\"\"\"\n",
    "        binary_score: str = Field(description=\"Score de pertinence 'yes' or 'no' \" )\n",
    "\n",
    "    # LLM\n",
    "    model = ChatOllama(temperature=0, model=\"mistral\", streaming=True)\n",
    "\n",
    "    llm_with_tool = model.with_structured_output(grade)\n",
    "\n",
    "    # Prompt\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "        Here is the retrieved document: \\n\\n {context} \\n\\n\n",
    "        Here is the user question: {question} \\n\n",
    "        If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\",\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "      \n",
    "    # Chain\n",
    "    chain = prompt | llm_with_tool\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    question = messages[0].content\n",
    "    docs = last_message.content\n",
    "\n",
    "    scored_result = chain.invoke({\"question\": question, \"context\": docs})\n",
    "\n",
    "    score = scored_result.binary_score\n",
    "\n",
    "    if score == \"yes\":\n",
    "        print(\"---DECISION: DOCS RELEVANT---\")\n",
    "        state[\"next\"] = \"hallucinations_grader\"\n",
    "    else:\n",
    "        print(\"---DECISION: DOCS NOT RELEVANT---\")\n",
    "        print(\"score = \", score)\n",
    "        state[\"next\"] = \"rewrite\"\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed8f0619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour ! Bien sûr que je peux t'aider avec ton RAG (Retrieval Augmented Generation). Qu'est ce qui te fait de la difficulté exactement ? Penses-tu avoir besoin d'aide pour créer un modèle de génération de texte augmenté de récupération de données, ou es-tu plutôt intéressé par l'utilisation d'un tel modèle ?\n"
     ]
    }
   ],
   "source": [
    "chat = ChatOllama(model=\"mistral\")\n",
    "response = chat.invoke([HumanMessage(content=\"Bonjour, es-tu prêt à m'aider avec mon RAG (Retrievel Augmented Generation) ?\")])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eeeffe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent(state):\n",
    "    \"\"\"\n",
    "    Appelle le modèle d'agent pour générer une réponse basée sur l'état actuel. Compte tenu de la question, il décidera de la récupérer à l'aide de l'outil de récupération ou de la terminer.\n",
    "\n",
    "    Args:\n",
    "        state(messages): L'état des messages du système.\n",
    "    Returns:\n",
    "    dict: L'état mis à jour avec la réponse de l'agent ajoutée aux messages\n",
    "    \"\"\"\n",
    "    print(\"---CALL AGENT---\")\n",
    "    messages = state[\"messages\"]\n",
    "    model = ChatOllama(model=\"mistral\", temperature=0, streaming=True)\n",
    "    model = model.bind_tools(tools)\n",
    "    response = model.invoke(messages)\n",
    "\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b62d430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite(state):\n",
    "    \"\"\"\n",
    "    Transforme  la requête pour produire une meilleure question.\n",
    "\n",
    "    Args:\n",
    "        state(messages): L'état des messages du système.\n",
    "\n",
    "    Returns:\n",
    "        dict: L'état mis à jour avec la question reformulée.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---TRANSFORM QUERY ---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "\n",
    "    msg = [\n",
    "        HumanMessage(\n",
    "            content=f\"\"\"\\n\n",
    "    Examine l'entrée et essaie de raisonner sur l'intention sémantique/le sens sous-jacent. \n",
    "    Voici la question initiale ::\n",
    "    \\n ------- \\n\n",
    "    {question} \n",
    "    \\n ------- \\n\n",
    "    Formulate an improved question: \"\"\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    model = ChatOllama(model=\"mistral\", temperature=0, streaming=True)\n",
    "    response = model.invoke(msg)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a5c3462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Génère une réponse\n",
    "   \n",
    "    Args:\n",
    "        state(messages): L'état des messages du système.\n",
    "   \n",
    "    Returns:\n",
    "        dict: L'état mis à jour avec la réponse générée.\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    messages = state[\"messages\"]  # Correction de l'orthographe de messages\n",
    "    question = messages[0].content\n",
    "    last_message = messages[-1]\n",
    "    docs = last_message.content\n",
    "    \n",
    "    # Créer notre propre prompt au lieu d'utiliser hub.pull\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"Vous êtes un assistant IA utile. Utilisez le contexte suivant pour répondre à la question de l'utilisateur.\n",
    "        Si vous ne connaissez pas la réponse, dites simplement que vous ne savez pas. N'essayez PAS d'inventer une réponse.\n",
    "        Si la question n'est pas liée au contexte, expliquez poliment que vous répondez seulement aux questions en rapport avec le contexte fourni.\n",
    "        \n",
    "        Contexte: {context}\"\"\"),\n",
    "        (\"human\", \"{question}\")\n",
    "    ])\n",
    "    \n",
    "    # LLM\n",
    "    llm = ChatOllama(model=\"mistral\", temperature=0, streaming=True)\n",
    "    \n",
    "    # Créer et exécuter la chaîne\n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "    response = rag_chain.invoke({\n",
    "        \"context\": docs,\n",
    "        \"question\": question\n",
    "    })\n",
    "    \n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ff032a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hallucinations_grader(state) -> Literal[\"generate\", \"rewrite\"]:\n",
    "    \"\"\"\n",
    "    Vérifie si la réponse générée contient des hallucinations.\n",
    "    \n",
    "    Args:\n",
    "        state (messages): L'état des messages du système.\n",
    "        \n",
    "    Returns:\n",
    "        str: Une décision quant à savoir si la réponse contient des hallucinations ou non\n",
    "    \"\"\"\n",
    "    print(\"---CHECK HALLUCINATIONS---\")\n",
    "\n",
    "    # Data model\n",
    "    class grade(BaseModel):\n",
    "        \"\"\"Score binaire pour la vérification de la pertinence.\"\"\"\n",
    "        binary_score: str = Field(description=\"Score de pertinence 'yes' or 'no' \" )\n",
    "\n",
    "    # LLM\n",
    "    model = ChatOllama(temperature=0, model=\"mistral\", streaming=True)\n",
    "\n",
    "    llm_with_tool = model.with_structured_output(grade)\n",
    "\n",
    "    # Prompt\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a grader assessing hallucinations in the generated response. \\n \n",
    "        Here is the generated response: \\n\\n {context} \\n\\n\n",
    "        Here is the user question: {question} \\n\n",
    "        If the response contains hallucinations, grade it as relevant. \\n\n",
    "        Give a binary score 'yes' or 'no' score to indicate whether the response contains hallucinations.\"\"\",\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "      \n",
    "    # Chain\n",
    "    chain = prompt | llm_with_tool\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    question = messages[0].content\n",
    "    docs = last_message.content\n",
    "\n",
    "    scored_result = chain.invoke({\"question\": question, \"context\": docs})\n",
    "\n",
    "    score = scored_result.binary_score\n",
    "\n",
    "    if score == \"yes\":\n",
    "        print(\"---DECISION: HALLUCINATIONS DETECTED---\")\n",
    "        state[\"next\"] = \"rewrite\"\n",
    "    else:\n",
    "        print(\"---DECISION: NO HALLUCINATIONS---\")\n",
    "        state[\"next\"] = \"generate\"\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df2487d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************Prompt[rlm/rag-prompt]********************\n",
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "Vous êtes un assistant IA utile. Utilisez le contexte suivant pour répondre à la question de l'utilisateur.\n",
      "    Si vous ne connaissez pas la réponse, dites simplement que vous ne savez pas. N'essayez PAS d'inventer une réponse.\n",
      "    Si la question n'est pas liée au contexte, expliquez poliment que vous répondez seulement aux questions en rapport avec le contexte fourni.\n",
      "    \n",
      "    Context: \u001b[33;1m\u001b[1;3m{context}\u001b[0m\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{question}\u001b[0m\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rag_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"Vous êtes un assistant IA utile. Utilisez le contexte suivant pour répondre à la question de l'utilisateur.\n",
    "    Si vous ne connaissez pas la réponse, dites simplement que vous ne savez pas. N'essayez PAS d'inventer une réponse.\n",
    "    Si la question n'est pas liée au contexte, expliquez poliment que vous répondez seulement aux questions en rapport avec le contexte fourni.\n",
    "    \n",
    "    Context: {context}\"\"\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "print(\"*\" * 20 + \"Prompt[rlm/rag-prompt]\" + \"*\" * 20)\n",
    "print(rag_prompt.pretty_print())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba526ee",
   "metadata": {},
   "source": [
    "## Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b10c8d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"agent\", agent)\n",
    "retrieve = ToolNode([retriever_tool])\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"grade_documents\", grade_documents)\n",
    "workflow.add_node(\"rewrite\", rewrite)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "workflow.add_node(\"hallucinations_grader\", hallucinations_grader)\n",
    "\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\", \n",
    "    tools_condition, \n",
    "    {\n",
    "        \"tools\": \"retrieve\",\n",
    "        END: END\n",
    "    })\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    lambda state: state[\"next\"],\n",
    "    {\n",
    "        \"hallucinations_grader\": \"hallucinations_grader\",  \n",
    "        \"rewrite\": \"rewrite\"                  \n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"generate\", \"hallucinations_grader\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"hallucinations_grader\",\n",
    "    lambda state: state[\"next\"],\n",
    "    {\n",
    "        \"generate\": END,                     \n",
    "        \"rewrite\": \"rewrite\"                \n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"rewrite\", \"agent\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "62bade1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CALL AGENT---\n",
      "\"Output from node 'agent':\"\n",
      "'---'\n",
      "{ 'messages': [ AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'mistral', 'created_at': '2025-04-16T13:31:56.11865122Z', 'done': True, 'done_reason': 'stop', 'total_duration': 6765337450, 'load_duration': 9775749, 'prompt_eval_count': 100, 'prompt_eval_duration': 246000000, 'eval_count': 290, 'eval_duration': 6508000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None), 'model_name': 'mistral'}, id='run-485b9b3e-6bce-4e85-a625-40728f1c1b33-0', tool_calls=[{'name': 'retrieve_apple_news', 'args': {'query': 'Palantir'}, 'id': '4891cecc-cc44-4582-883c-62bc5cc028e0', 'type': 'tool_call'}], usage_metadata={'input_tokens': 100, 'output_tokens': 290, 'total_tokens': 390})]}\n",
      "'\\n---\\n'\n",
      "\"Output from node 'retrieve':\"\n",
      "'---'\n",
      "{ 'messages': [ ToolMessage(content='Still, for long-term, growth-oriented investors, Palantir is a name worth considering, given the soaring demand for its products and its improving fundamentals.\\n\\nStill, for long-term, growth-oriented investors, Palantir is a name worth considering, given the soaring demand for its products and its improving fundamentals.\\n\\nPalantir grew revenue by 17% year over year. Trailing-12-month revenue hit $2.1 billion, gross profit swelled to $1.7 billion, and free cash flow increased to $474 million.\\n\\nPalantir grew revenue by 17% year over year. Trailing-12-month revenue hit $2.1 billion, gross profit swelled to $1.7 billion, and free cash flow increased to $474 million.', name='retrieve_apple_news', id='aaf1c475-9d7e-4a3a-b34f-d54e56a578ff', tool_call_id='4891cecc-cc44-4582-883c-62bc5cc028e0')]}\n",
      "'\\n---\\n'\n",
      "---CHECK RELEVANCE---\n",
      "---DECISION: DOCS NOT RELEVANT---\n",
      "score =  no\n",
      "\"Output from node 'grade_documents':\"\n",
      "'---'\n",
      "{ 'messages': [ HumanMessage(content='Qui est Palantir ?', additional_kwargs={}, response_metadata={}, id='b220a910-6a3d-4f35-b87c-9658886dbfc2'),\n",
      "                AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'mistral', 'created_at': '2025-04-16T13:31:56.11865122Z', 'done': True, 'done_reason': 'stop', 'total_duration': 6765337450, 'load_duration': 9775749, 'prompt_eval_count': 100, 'prompt_eval_duration': 246000000, 'eval_count': 290, 'eval_duration': 6508000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None), 'model_name': 'mistral'}, id='run-485b9b3e-6bce-4e85-a625-40728f1c1b33-0', tool_calls=[{'name': 'retrieve_apple_news', 'args': {'query': 'Palantir'}, 'id': '4891cecc-cc44-4582-883c-62bc5cc028e0', 'type': 'tool_call'}], usage_metadata={'input_tokens': 100, 'output_tokens': 290, 'total_tokens': 390}),\n",
      "                ToolMessage(content='Still, for long-term, growth-oriented investors, Palantir is a name worth considering, given the soaring demand for its products and its improving fundamentals.\\n\\nStill, for long-term, growth-oriented investors, Palantir is a name worth considering, given the soaring demand for its products and its improving fundamentals.\\n\\nPalantir grew revenue by 17% year over year. Trailing-12-month revenue hit $2.1 billion, gross profit swelled to $1.7 billion, and free cash flow increased to $474 million.\\n\\nPalantir grew revenue by 17% year over year. Trailing-12-month revenue hit $2.1 billion, gross profit swelled to $1.7 billion, and free cash flow increased to $474 million.', name='retrieve_apple_news', id='aaf1c475-9d7e-4a3a-b34f-d54e56a578ff', tool_call_id='4891cecc-cc44-4582-883c-62bc5cc028e0')]}\n",
      "'\\n---\\n'\n",
      "---TRANSFORM QUERY ---\n",
      "\"Output from node 'rewrite':\"\n",
      "'---'\n",
      "{ 'messages': [ AIMessage(content=' What or who is Palantir Technologies? (Palantir is a company, and the question is asking for information about it.)', additional_kwargs={}, response_metadata={'model': 'mistral', 'created_at': '2025-04-16T13:31:57.21320009Z', 'done': True, 'done_reason': 'stop', 'total_duration': 644686763, 'load_duration': 3791383, 'prompt_eval_count': 81, 'prompt_eval_duration': 11000000, 'eval_count': 29, 'eval_duration': 628000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None), 'model_name': 'mistral'}, id='run-06d52c8d-a38b-4241-ad31-16e6c35a5bc4-0', usage_metadata={'input_tokens': 81, 'output_tokens': 29, 'total_tokens': 110})]}\n",
      "'\\n---\\n'\n",
      "---CALL AGENT---\n",
      "\"Output from node 'agent':\"\n",
      "'---'\n",
      "{ 'messages': [ AIMessage(content=' Palantir Technologies is an American software company that provides big data analytics and cloud services to various government agencies and private corporations. It was founded in 2003 by Peter Thiel, Alex Karp, and Joe Lonsdale. The name \"Palantir\" comes from a magical crystal ball used for seeing distant events in J.R.R. Tolkien\\'s Middle-earth legendarium. Palantir\\'s software helps organizations make sense of large amounts of data by integrating disparate data sources and providing insights to inform decision-making processes. The company went public through a direct listing on the New York Stock Exchange in September 2020.', additional_kwargs={}, response_metadata={'model': 'mistral', 'created_at': '2025-04-16T13:31:59.896472756Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3267005705, 'load_duration': 3845520, 'prompt_eval_count': 257, 'prompt_eval_duration': 30000000, 'eval_count': 142, 'eval_duration': 3229000000, 'message': Message(role='assistant', content=' Palantir Technologies is an American software company that provides big data analytics and cloud services to various government agencies and private corporations. It was founded in 2003 by Peter Thiel, Alex Karp, and Joe Lonsdale. The name \"Palantir\" comes from a magical crystal ball used for seeing distant events in J.R.R. Tolkien\\'s Middle-earth legendarium. Palantir\\'s software helps organizations make sense of large amounts of data by integrating disparate data sources and providing insights to inform decision-making processes. The company went public through a direct listing on the New York Stock Exchange in September 2020.', images=None, tool_calls=None), 'model_name': 'mistral'}, id='run-a377a5f3-def7-4d63-a463-d82702572677-0', usage_metadata={'input_tokens': 257, 'output_tokens': 142, 'total_tokens': 399})]}\n",
      "'\\n---\\n'\n"
     ]
    }
   ],
   "source": [
    "inputs = {\n",
    "    \"messages\": [\n",
    "        (\"user\", \"Qui est Palantir ?\")\n",
    "    ]\n",
    "}\n",
    "\n",
    "for output in graph.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint.pprint(f\"Output from node '{key}':\")\n",
    "        pprint.pprint(\"---\")\n",
    "        pprint.pprint(value, indent=2, width=80, depth=None)\n",
    "    pprint.pprint(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d524860",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
