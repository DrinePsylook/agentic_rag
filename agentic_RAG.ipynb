{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9076dd4d",
   "metadata": {},
   "source": [
    "# Agentic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f81d636f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "from dotenv import load_dotenv\n",
    "from typing import Annotated, Sequence, Literal\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader, csv_loader\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "713f7f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0273e01f",
   "metadata": {},
   "source": [
    "## Téléchargement du CSV\n",
    "\n",
    "Arguments ajoutées pour que les métadonnées prennent en compte la date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e05c1932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 documents from CSV file.\n",
      "First document metadata:\n",
      "{'source': 'datas/short_APPL.csv', 'row': 0, 'date': '2023-12-16 22:00:00 UTC'}\n",
      "First document content:\n",
      ": 0\n",
      "article: After an absolute disaster of a year in 2022, the stock market appears to have turned the corner. Each of the major market indexes has gained more than 20% from their respective trough. Perhaps more importantly, the S&P 500 and the Nasdaq Composite are within striking distance of new highs, which will check the final box marking the start of a new bull market.\n",
      "Closing out the old and ringing in the new is a great time for examination, and one of the places I start is with my portfolio. A review of my top investments and how they came to be that way can offer valuable insight for the future.\n",
      "Here's a look at my six largest holdings heading into 2024 (as of the market close on Dec. 15) and the incredibly valuable lesson I learned from each one.\n",
      "Image source: Getty Images.\n",
      "No. 6: Nvidia\n",
      "Every investor has one -- the \"stock that got away.\" The one you meant to buy, only to find that it got away from you and has risen 100%, 500%, or even 1,000%. In my case, that stock was Nvidia (NASDAQ: NVDA). I had owned a few shares of the graphics processing units (GPU) pioneer in the early days of my investing journey but ultimately sold them in an unprovoked bid of tax-loss harvesting in early 2010.\n",
      "I always meant to buy it back, but the stock price meandered for much of the next five years, and I ultimately lost confidence. Things changed quickly in 2016 when the stock tripled. After that, it just kept getting away from me.\n",
      "Fast forward to early 2018. Nvidia still dominated the discrete desktop GPU space, controlling roughly 70% of the market. The company's graphics cards were the processor of choice for cryptocurrency mining, which was booming. Furthermore, there was an ongoing push toward autonomous driving. It was clear that CEO Jensen Huang had a knack for skating to where the puck was going -- recognizing technology trends on the fly and adapting Nvidia's processors and the accompanying software to meet that need.\n",
      "After much deliberation, I held my nose and bought Nvidia anyway -- even though the stock had risen 600% over the preceding two years. I have added to my stake several times since. Over the past few years, Nvidia has once again adapted to meet a compelling technology need, becoming the gold standard for generative AI applications.\n",
      "Since that initial purchase, Nvidia has soared 768%, and the stock has become my sixth-largest holding, amounting to nearly 6% of my portfolio. The lesson here? It's never too late to buy a quality company, even if the stock has already risen many times over.\n",
      "No. 5 and 4: Shopify and Amazon\n",
      "Long after Amazon had established itself as the world's largest digital retailer, Shopify (NYSE: SHOP) came on the scene with a different approach to e-commerce. Shopify's founders, having discovered firsthand the difficulties inherent in starting an online sales platform, pivoted the business from selling snowboards to providing customizable templates and other tools that made setting up and running an e-commerce business a snap.\n",
      "By solving a common problem among digital retailers, Shopify carved out a profitable niche for itself in a market that was already (and still is) dominated by Amazon. While it isn't an exact apples-to-apples comparison, it helps illustrate an age-old truth in investing that I learned from owning this stock -- there's a Pepsi for every Coke.\n",
      "There's another lesson here. I had long been a shareholder of Amazon, but I recognized the value Shopify could bring to the online sales space. Despite the fact that e-commerce was already well represented in my portfolio, I made a sizable investment in Shopify.\n",
      "That decision turned out well, as both companies have continued to prosper in the age of digital retail. It also turned out well for me as an investor. Since my first purchase of Shopify shares, the stock is up more than 1,446%, while Amazon has gained 844%. Shopify and Amazon are my fourth and fifth largest holdings heading into 2024, each representing roughly 6% of my portfolio.\n",
      "No. 3: Apple\n",
      "There's little question that Apple (NASDAQ: AAPL) has become one of the most successful companies in history. Yet, at times over the past few years, some investors concluded the company had reached its zenith. Apple reached a market cap of $1 trillion in 2018, so how much higher could it go?\n",
      "There were other worries. As penetration has risen, global smartphone sales have slowed. Since Apple's flagship product -- the iPhone -- historically generates more than half the company's revenue, investor reservations are understandable.\n",
      "Despite these challenges, Apple has continued to grow. CEO Tim Cook has succeeded in expanding Apple's services business to become the company's second-biggest breadwinner, behind just the iPhone. The segment brought in $85 billion in fiscal 2023 (ended Sept. 30), making it comparable to a top 50 company in the Fortune 500. Furthermore, the iPhone continues to dominate where it matters, capturing a record 45% of worldwide smartphone revenue and 85% of profits in the second quarter, according to Counterpoint Research.\n",
      "Fears that Apple simply couldn't go any higher turned out to be unfounded, an important lesson for investors as its market cap has tripled since 2018. Since my first purchase in 2008, Apple's stock price has surged more than 3,400% to become my third-largest position at 8% of my portfolio. I'm confident there's more to come.\n",
      "No. 2: Mercadolibre\n",
      "It's likely that many investors have never heard of MercadoLibre (NASDAQ: MELI). The company, which began as a local online auction site, has evolved into the largest e-commerce and payments ecosystem in Latin America, serving 18 countries in the region.\n",
      "MercadoLibre not only provides a marketplace for buyers and sellers but also handles shipping and logistics, warehouse and cross-docking, digital payments, consumer and merchant financing, digital wallets, and more. Think of it as the Amazon, Shopify, and PayPal of Latin America all rolled into one.\n",
      "Many investors have avoided the stock because of the risks inherent in the region, which is understandable. For example, Argentina -- MercadoLibre's birthplace and one of its biggest markets -- has an inflation rate that clocks in at 143%, and the country just devalued its currency by 50%. Other countries in the region grapple with hyperinflation, economic turmoil, charges of political corruption, poor infrastructure, and more.\n",
      "Yet those risks pale in the context of the opportunity. Latin America is years behind the U.S. in terms of e-commerce and digital payment penetration, yet adoption continues to grow. Furthermore, Latin America has twice the population of the U.S. and is the fastest-growing e-commerce market in the world, according to Americas Market Intelligence. Finally, because MercadoLibre takes a cut of each transaction, it has sidestepped many of those risks. As a result, its revenue grew 50% in 2022 while net income soared 480%, a trend that has been ongoing for more than a decade.\n",
      "Understanding the risk, viewed through the lens of the significant long-term opportunity, can provide important insight, which gave me the confidence to buy the stock. My rather modest initial investment in MercadoLibre in 2009 has grown by more than 7,300%, and the company now represents 10% of my portfolio. Not bad for a \"risky\" stock.\n",
      "No. 1: Netflix\n",
      "Netflix (NASDAQ: NFLX) was the very first stock I bought when I started investing in late 2007. After incurring a late fee at Blockbuster (remember them?) that was more than the cost of buying the movie new, I cut up my membership card and subscribed to Netflix. As an extremely satisfied customer, it made perfect sense to buy the stock once I started investing.\n",
      "Back then, the company was a DVD-by-mail service that had recently begun experimenting with streaming video. Netflix had achieved remarkable penetration in its earliest markets, and I surmised the company could expand its success across the country, which was the basis of my investing thesis.\n",
      "The company has achieved all that and more, becoming the world's largest subscription streaming video service. The value of the initial shares I bought in 2007 has surged more than 19,000%, making Netflix my largest holding at nearly 11% of my portfolio.\n",
      "However, those life-changing gains were only possible because I held the stock for the duration, which is easier said than done. Remember the \"Qwikster\" fiasco of 2011? All the \"Netflix killers\" over the years? How about the loss of 1.2 million subscribers early last year?\n",
      "There were plenty of excuses to sell Netflix over the years, but for me, the investing thesis never changed, so I held on. And this long-term buy-and-hold strategy continues to win out.\n",
      "Should you invest $1,000 in Nvidia right now?\n",
      "Before you buy stock in Nvidia, consider this:\n",
      "The Motley Fool Stock Advisor analyst team just identified what they believe are the 10 best stocks for investors to buy now... and Nvidia wasn't one of them. The 10 stocks that made the cut could produce monster returns in the coming years.\n",
      "Stock Advisor provides investors with an easy-to-follow blueprint for success, including guidance on building a portfolio, regular updates from analysts, and two new stock picks each month. The Stock Advisor service has more than tripled the return of S&P 500 since 2002*.\n",
      "See the 10 stocks\n",
      "*Stock Advisor returns as of December 11, 2023\n",
      "John Mackey, former CEO of Whole Foods Market, an Amazon subsidiary, is a member of The Motley Fool’s board of directors. Danny Vena has positions in Amazon, Apple, MercadoLibre, Netflix, Nvidia, PayPal, and Shopify and has the following options: long January 2024 $95 calls on PayPal. The Motley Fool has positions in and recommends Amazon, Apple, MercadoLibre, Netflix, Nvidia, PayPal, and Shopify. The Motley Fool recommends the following options: long January 2024 $47.50 calls on Coca-Cola and short December 2023 $67.50 puts on PayPal. The Motley Fool has a disclosure policy.\n",
      "The views and opinions expressed herein are the views and opinions of the author and do not necessarily reflect those of Nasdaq, Inc.\n"
     ]
    }
   ],
   "source": [
    "loader = csv_loader.CSVLoader(\n",
    "    file_path=\"datas/short_APPL.csv\",\n",
    "    metadata_columns=[\"date\"],\n",
    "    encoding=\"utf-8\",\n",
    "    csv_args={\n",
    "        \"delimiter\": \",\",\n",
    "        \"quotechar\": '\"',\n",
    "    })\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(docs)} documents from CSV file.\")\n",
    "print(f\"First document metadata:\\n{docs[0].metadata}\")\n",
    "print(f\"First document content:\\n{docs[0].page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20677602",
   "metadata": {},
   "source": [
    "## Encodage\n",
    "\n",
    "split le document en chunks<br/>\n",
    "et embedding avec un modèle HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2dddada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 173\n",
      "First chunk: : 0\n",
      "article: After an absolute disaster of a year in 2022, the stock market appears to have turned the corner. Each of the major market indexes has gained more than 20% from their respective trough. Perhaps more importantly, the S&P 500 and the Nasdaq Composite are within striking distance of new highs, which will check the final box marking the start of a new bull market.\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=50,\n",
    ")\n",
    "docs_splits = text_splitter.split_documents(docs)\n",
    "print(f\"Total chunks: {len(docs_splits)}\")\n",
    "print(f\"First chunk: {docs_splits[0].page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3bee76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte : : 0\n",
      "article: After an absolute disaster of a year in 2022, the stock market appears to have turned the corner. Each of the major market indexes has gained more than 20% from their respective trough. Perhaps more importantly, the S&P 500 and the Nasdaq Composite are within striking distance of new highs, which will check the final box marking the start of a new bull market.\n",
      "Date : 2023-12-16 22:00:00 UTC\n",
      "------\n",
      "Texte : Closing out the old and ringing in the new is a great time for examination, and one of the places I start is with my portfolio. A review of my top investments and how they came to be that way can offer valuable insight for the future.\n",
      "Here's a look at my six largest holdings heading into 2024 (as of the market close on Dec. 15) and the incredibly valuable lesson I learned from each one.\n",
      "Image source: Getty Images.\n",
      "No. 6: Nvidia\n",
      "Date : 2023-12-16 22:00:00 UTC\n",
      "------\n",
      "Texte : Every investor has one -- the \"stock that got away.\" The one you meant to buy, only to find that it got away from you and has risen 100%, 500%, or even 1,000%. In my case, that stock was Nvidia (NASDAQ: NVDA). I had owned a few shares of the graphics processing units (GPU) pioneer in the early days of my investing journey but ultimately sold them in an unprovoked bid of tax-loss harvesting in early 2010.\n",
      "Date : 2023-12-16 22:00:00 UTC\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "for chunk in docs_splits[:3]:\n",
    "    print(\"Texte :\", chunk.page_content)\n",
    "    print(\"Date :\", chunk.metadata.get(\"date\"))\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ef597fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1039396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = \"./chroma_db\"\n",
    "os.makedirs(persist_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bee9c33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorestore = Chroma.from_documents(\n",
    "    documents=docs_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "retriever = vectorestore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "35850bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retrieve_apple_news\",\n",
    "    \"Search and return information from press articles about Apple Inc., including news related to its stock market activity, financial performance, and business developments.\",\n",
    ")\n",
    "tools = [retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "047d1500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.4\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "print(chromadb.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06994da3",
   "metadata": {},
   "source": [
    "## Agent State\n",
    "\n",
    "Création de la classe AgentState\n",
    "création des différentes Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c764aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "   messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedce291",
   "metadata": {},
   "source": [
    "différentes fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "012ddcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_documents(state) -> Literal[\"generate\", \"rewrite\"]:\n",
    "    \"\"\"\n",
    "    Détermine si les documents récupérés sont pertinents par rapport à la question.\n",
    "    \n",
    "    Args :\n",
    "        state (messages): L'état des messages du système.\n",
    "        \n",
    "    Returns :\n",
    "        str: Une décision quant à savoir si les documents sont pertinents ou non\n",
    "    \"\"\"\n",
    "    print(\"---CHECK RELEVANCE---\")\n",
    "\n",
    "    # Data model\n",
    "    class grade(BaseModel):\n",
    "        \"\"\"Score binaire pour la vérification de la pertinence.\"\"\"\n",
    "        binary_score: str = Field(description=\"Score de pertinence 'yes' or 'no' \" )\n",
    "\n",
    "    # LLM\n",
    "    model = ChatOllama(temperature=0, model=\"mistral\", streaming=True)\n",
    "\n",
    "    llm_with_tool = model.with_structured_output(grade)\n",
    "\n",
    "    # Prompt\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "        Here is the retrieved document: \\n\\n {context} \\n\\n\n",
    "        Here is the user question: {question} \\n\n",
    "        If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\",\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "      \n",
    "    # Chain\n",
    "    chain = prompt | llm_with_tool\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    question = messages[0].content\n",
    "    docs = last_message.content\n",
    "\n",
    "    scored_result = chain.invoke({\"question\": question, \"context\": docs})\n",
    "\n",
    "    score = scored_result.binary_score\n",
    "\n",
    "    if score == \"yes\":\n",
    "        print(\"---DECISION: DOCS RELEVANT---\")\n",
    "        return \"generate\"\n",
    "    else:\n",
    "        print(\"---DECISION: DOCS NOT RELEVANT---\")\n",
    "        print(score)\n",
    "        return \"rewrite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ed8f0619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour ! Je suis prêt à vous aider avec votre RAG (Retrieval Augmented Generation). Si vous avez des questions ou besoin d'explications sur le processus, n'hésitez pas à me les demander.\n",
      "\n",
      "Le RAG est une technique de génération de texte qui utilise un modèle de langage pré-entrainé pour générer une réponse à une question. Les données utilisées pour l'entraînement de ce modèle sont composées de paires de questions/réponses, où la réponse est un extract de texte trouvé dans une source de données externe (par exemple, Wikipédia).\n",
      "\n",
      "Lorsque le modèle reçoit une nouvelle question, il tente de générer une réponse en utilisant les connaissances qu'il a acquises grâce à l'entraînement, et si nécessaire, il recherche des informations supplémentaires dans la source de données externe pour améliorer sa réponse.\n"
     ]
    }
   ],
   "source": [
    "chat = ChatOllama(model=\"mistral\")\n",
    "response = chat.invoke([HumanMessage(content=\"Bonjour, es-tu prêt à m'aider avec mon RAG (Retrievel Augmented Generation) ?\")])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eeeffe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent(state):\n",
    "    \"\"\"\n",
    "    Appelle le modèle d'agent pour générer une réponse basée sur l'état actuel. Compte tenu de la question, il décidera de la récupérer à l'aide de l'outil de récupération ou de la terminer.\n",
    "\n",
    "    Args:\n",
    "        state(messages): L'état des messages du système.\n",
    "    Returns:\n",
    "    dict: L'état mis à jour avec la réponse de l'agent ajoutée aux messages\n",
    "    \"\"\"\n",
    "    print(\"---CALL AGENT---\")\n",
    "    messages = state[\"messages\"]\n",
    "    model = ChatOllama(model=\"mistral\", temperature=0, streaming=True)\n",
    "    model = model.bind_tools(tools)\n",
    "    response = model.invoke(messages)\n",
    "\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5b62d430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite(state):\n",
    "    \"\"\"\n",
    "    Transforme  la requête pour produire une meilleure question.\n",
    "\n",
    "    Args:\n",
    "        state(messages): L'état des messages du système.\n",
    "\n",
    "    Returns:\n",
    "        dict: L'état mis à jour avec la question reformulée.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---TRANSFORM QUERY ---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "\n",
    "    msg = [\n",
    "        HumanMessage(\n",
    "            content=f\"\"\"\\n\n",
    "    Examine l'entrée et essaie de raisonner sur l'intention sémantique/le sens sous-jacent. \n",
    "    Voici la question initiale ::\n",
    "    \\n ------- \\n\n",
    "    {question} \n",
    "    \\n ------- \\n\n",
    "    Formulate an improved question: \"\"\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    model = ChatOllama(model=\"mistral\", temperature=0, streaming=True)\n",
    "    response = model.invoke(msg)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8a5c3462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Génère une réponse\n",
    "   \n",
    "    Args:\n",
    "        state(messages): L'état des messages du système.\n",
    "   \n",
    "    Returns:\n",
    "        dict: L'état mis à jour avec la réponse générée.\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    messages = state[\"messages\"]  # Correction de l'orthographe de messages\n",
    "    question = messages[0].content\n",
    "    last_message = messages[-1]\n",
    "    docs = last_message.content\n",
    "    \n",
    "    # Créer notre propre prompt au lieu d'utiliser hub.pull\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"Vous êtes un assistant IA utile. Utilisez le contexte suivant pour répondre à la question de l'utilisateur.\n",
    "        Si vous ne connaissez pas la réponse, dites simplement que vous ne savez pas. N'essayez PAS d'inventer une réponse.\n",
    "        Si la question n'est pas liée au contexte, expliquez poliment que vous répondez seulement aux questions en rapport avec le contexte fourni.\n",
    "        \n",
    "        Contexte: {context}\"\"\"),\n",
    "        (\"human\", \"{question}\")\n",
    "    ])\n",
    "    \n",
    "    # LLM\n",
    "    llm = ChatOllama(model=\"mistral\", temperature=0, streaming=True)\n",
    "    \n",
    "    # Créer et exécuter la chaîne\n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "    response = rag_chain.invoke({\n",
    "        \"context\": docs,\n",
    "        \"question\": question\n",
    "    })\n",
    "    \n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "df2487d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************Prompt[rlm/rag-prompt]********************\n",
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "Vous êtes un assistant IA utile. Utilisez le contexte suivant pour répondre à la question de l'utilisateur.\n",
      "    Si vous ne connaissez pas la réponse, dites simplement que vous ne savez pas. N'essayez PAS d'inventer une réponse.\n",
      "    Si la question n'est pas liée au contexte, expliquez poliment que vous répondez seulement aux questions en rapport avec le contexte fourni.\n",
      "    \n",
      "    Context: \u001b[33;1m\u001b[1;3m{context}\u001b[0m\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{question}\u001b[0m\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rag_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"Vous êtes un assistant IA utile. Utilisez le contexte suivant pour répondre à la question de l'utilisateur.\n",
    "    Si vous ne connaissez pas la réponse, dites simplement que vous ne savez pas. N'essayez PAS d'inventer une réponse.\n",
    "    Si la question n'est pas liée au contexte, expliquez poliment que vous répondez seulement aux questions en rapport avec le contexte fourni.\n",
    "    \n",
    "    Context: {context}\"\"\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "print(\"*\" * 20 + \"Prompt[rlm/rag-prompt]\" + \"*\" * 20)\n",
    "print(rag_prompt.pretty_print())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba526ee",
   "metadata": {},
   "source": [
    "## Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b10c8d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"agent\", agent)\n",
    "retrieve = ToolNode([retriever_tool])\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"rewrite\", rewrite)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\", \n",
    "    tools_condition, \n",
    "    {\n",
    "        \"tools\": \"retrieve\",\n",
    "        END: END\n",
    "    })\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve\",\n",
    "    grade_documents\n",
    ")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "workflow.add_edge(\"rewrite\", \"agent\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "62bade1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CALL AGENT---\n",
      "\"Output from node 'agent':\"\n",
      "'---'\n",
      "{ 'messages': [ AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'mistral', 'created_at': '2025-04-15T14:04:15.697310267Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3724443263, 'load_duration': 4569199, 'prompt_eval_count': 115, 'prompt_eval_duration': 228000000, 'eval_count': 159, 'eval_duration': 3490000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None), 'model_name': 'mistral'}, id='run-ad3192db-e19c-4c5d-b8e0-cb5a99df364a-0', tool_calls=[{'name': 'retrieve_apple_news', 'args': {'query': 'positionnement Alphabet en intelligence artificielle'}, 'id': 'f6f571b0-7eee-483f-abec-a73c79bcf6e7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 115, 'output_tokens': 159, 'total_tokens': 274})]}\n",
      "'\\n---\\n'\n",
      "---CHECK RELEVANCE---\n",
      "---DECISION: DOCS RELEVANT---\n",
      "\"Output from node 'retrieve':\"\n",
      "'---'\n",
      "{ 'messages': [ ToolMessage(content='However, Alphabet has responded with its own generative AI tool called Bard. While the tools offer similar results, Bard was first in producing more up-to-date results as it leverages Google\\'s search engine.\\nMoreover, the company has a long history with AI. Alphabet first used AI to correct spelling as early as 2001. The tools advanced from that point, so much so that Alphabet declared itself an \"AI first\" company in 2016.\\n\\nMoreover, the company has a long history with AI. Alphabet first used AI to correct spelling as early as 2001. The tools advanced from that point, so much so that Alphabet declared itself an \"AI first\" company in 2016.\\nFurthermore, investors should remember that Alphabet owns numerous companies, some of which could drive AI innovation. Earlier this year, it combined two of its AI companies into Google DeepMind. This subsidiary is a group of scientists, engineers, and others researching AI.\\n\\nIt\\'s way too early to count out this \"AI-first\" company\\nWill Healy (Alphabet): The narrative in the AI space seems to have turned away from Google parent Alphabet (NASDAQ: GOOGL) (NASDAQ: GOOG).\\n\\nShould you invest $1,000 in Alphabet right now?\\nBefore you buy stock in Alphabet, consider this:\\nThe Motley Fool Stock Advisor analyst team just identified what they believe are the 10 best stocks for investors to buy now... and Alphabet wasn\\'t one of them. The 10 stocks that made the cut could produce monster returns in the coming years.', name='retrieve_apple_news', id='4f9b87fa-d51f-438e-bd0a-3e8e6eb196d2', tool_call_id='f6f571b0-7eee-483f-abec-a73c79bcf6e7')]}\n",
      "'\\n---\\n'\n",
      "---GENERATE---\n",
      "\"Output from node 'generate':\"\n",
      "'---'\n",
      "{ 'messages': [ ' En ce moment, Alphabet se place comme une entreprise '\n",
      "                '\"première de l\\'intelligence artificielle\" dans le secteur. '\n",
      "                \"Cela signifie qu'elle considère l'IA comme étant un élément \"\n",
      "                \"clé de son développement et de ses stratégies d'affaires. En \"\n",
      "                \"effet, elle a commencé à utiliser l'IA pour la correction \"\n",
      "                'orthographique dès 2001, puis a avancé dans ce domaine '\n",
      "                'jusqu\\'à se déclarer une \"entreprise AI-first\" en 2016. De '\n",
      "                'plus, Alphabet possède de nombreuses autres entreprises qui '\n",
      "                \"peuvent contribuer à l'innovation en matière d'IA. Par \"\n",
      "                'exemple, il a récemment fusionné deux de ses entreprises en '\n",
      "                'AI pour former Google DeepMind, une filiale constituée de '\n",
      "                'scientifiques, ingénieurs et autres chercheurs en AI. '\n",
      "                'Cependant, il est important de noter que les analystes de The '\n",
      "                \"Motley Fool Stock Advisor n'ont pas recommandé d'investir \"\n",
      "                'dans Alphabet à ce moment-là.']}\n",
      "'\\n---\\n'\n"
     ]
    }
   ],
   "source": [
    "inputs = {\n",
    "    \"messages\": [\n",
    "        (\"user\", \"Quel est le positionnement d'Alphabet face à la concurrence en intelligence artificielle ?\")\n",
    "    ]\n",
    "}\n",
    "\n",
    "for output in graph.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint.pprint(f\"Output from node '{key}':\")\n",
    "        pprint.pprint(\"---\")\n",
    "        pprint.pprint(value, indent=2, width=80, depth=None)\n",
    "    pprint.pprint(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d524860",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
